{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "# Chapter 9. ESNの内部結合の学習\n",
                "\n",
                "[en]: #\n",
                "# Chapter 9. Optimizing the ESN's Internal Connection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "この章では、前章の手法を発展させ、ESNの内部結合をオンライン学習で調整する手法を扱います。\n",
                "\n",
                "**注意:** この章のコードはGoogle Colaboratory上では動作しません。READMEを参照の上、ローカル環境を構築し、その上で実行してください。\n",
                "\n",
                "[en]: #\n",
                "In this chapter, you will learn about RC schemes that adjust the internal connections of ESNs through online learning.\n",
                "\n",
                "**Note:** The code in this chapter does not work on Google Colaboratory.\n",
                "Please refer to the README to set up a local environment and run the code there."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "## 前書き\n",
                "\n",
                "[en]: #\n",
                "## Introduction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "通常、ESNを用いたRCではESNの内部結合は固定されます。\n",
                "一方で内部結合は、前回議論されたように、閉ループの一種としてみなせます。\n",
                "例えば以下のESNを考えます。\n",
                "\n",
                "[en]: #\n",
                "In standard ESN setups, the internal connections of the ESN are fixed.\n",
                "The internal weight, however, can be considered a type of closed loop.\n",
                "For example, consider the following ESN:\n",
                "\n",
                "[END]: #\n",
                "\n",
                "$$\n",
                "\\begin{align*}\n",
                "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed} y[k] \\right)\\\\\n",
                "y[k] &= W^\\mathrm{out}x[k]\n",
                ",\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "この時、 $y[k]$ を代入すると以下の式になります。\n",
                "\n",
                "[en]: #\n",
                "which can be rewritten as the following equation:\n",
                "\n",
                "[END]: #\n",
                "$$\n",
                "\\begin{align*}\n",
                "x[k+1] &= \\tanh\\left(\\rho W^\\mathrm{rec} x[k] + W^\\mathrm{in} u[k+1]+ W^\\mathrm{feed}W^\\mathrm{out}x[k] \\right)\\\\\n",
                "&= \\tanh\\left(\\left(\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}\\right) x[k] + W^\\mathrm{in} u[k+1] \\right)\n",
                ".\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "つまり内部結合が $\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}$ とみなせます。\n",
                "また逆の操作で、あるESN上の $i$ 番目のノードに結合する前結合 $W^\\mathrm{rec}_{i~\\cdot}$ 、後結合 $W^\\mathrm{rec}_{\\cdot~i}$ をそれぞれ $W^\\mathrm{out}$、$W^\\mathrm{feed}$ として内部結合を閉ループとして外部化できます。\n",
                "あとは前章の閉ループの学習プロセスで調整すれば内部結合を調整できます。\n",
                "ここで新たにどのように目標時系列を指定するか問題となります。\n",
                "\n",
                "今回紹介する **生得的学習 (innate training)**<sup>[1]</sup>ならびに **full-FORCE**<sup>[2]</sup>はいずれも別のESNを用いて目標時系列を生成し、FORCE学習<sup>[3]</sup>によって学習を達成します。\n",
                "以下その概要を説明します。\n",
                "\n",
                "[en]: #\n",
                "In other words, the internal connection can be viewed as $\\rho W^\\mathrm{rec} + W^\\mathrm{feed}W^\\mathrm{out}$.\n",
                "Conversely, the pre-synaptic connection $W^\\mathrm{rec}_{i~\\cdot}$ and the post-synaptic connection $W^\\mathrm{rec}_{\\cdot~i}$ of the $i$-th node can be externalized as $W^\\mathrm{out}$ and $W^\\mathrm{feed}$ in a feedback loop, respectively.\n",
                "This means that internal connections can be adjusted using the closed-loop learning methods introduced in the previous chapter.\n",
                "A new question then arises: how to specify the target time-series data for the internal connection.\n",
                "Both **innate training**<sup>[1]</sup> and **full-FORCE**<sup>[2]</sup> generate a target time series using a different ESN and train the internal connection with FORCE learning<sup>[3]</sup>."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "### 生得的学習\n",
                "\n",
                "[en]: #\n",
                "### Innate training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "**生得的学習**<sup>[1]</sup> はR. Lajeらによって提案されたESNの内部結合を調整するオンライン学習法の一種です。\n",
                "生得的学習の特徴的な点はその目標時系列の指定方法です。\n",
                "特にカオスESNを用意し、ある入力が与えられた後のカオスESNの内部状態の時系列を、別のESNで一定期間再現的に生成するように内部結合が学習されます。\n",
                "またこの目標となる軌道は **生得的軌道 (innate trajectory)** と呼ばれます。\n",
                "\n",
                "生得的学習の学習プロセスは、事前学習と事後学習の2段階に分けられます。\n",
                "事前学習では、FORCE学習<sup>[3]</sup>を用いて内部結合が調整されます。\n",
                "事後学習は、通常のRCと同様に、事前学習の後に行われます。\n",
                "すなわち開ループ系で特定の軌道を出力するようにリードアウト層が学習されます。\n",
                "このときのコスト関数 $C(W^\\mathrm{rec})$ は以下のとおり表されます。\n",
                "\n",
                "[en]: #\n",
                "**Innate training**<sup>[1]</sup> is an online learning method that adjusts the internal connections of ESNs, proposed by R. Laje et al.\n",
                "Innate training uses a chaotic ESN, and another ESN's internal connections are tuned to reproducibly generate the chaotic dynamics over a certain period.\n",
                "This target trajectory is called an **innate trajectory**.\n",
                "\n",
                "The learning process consists of pre-training and post-training.\n",
                "In pre-training, the internal connections are adjusted using FORCE learning<sup>[3]</sup>.\n",
                "Post-training is performed after pre-training, similar to standard RC.\n",
                "In other words, the readout layer is trained to output a specific trajectory in an open-loop system.\n",
                "The cost function $C(W^\\mathrm{rec})$ of the pre-training is expressed as follows:\n",
                "\n",
                "[END]: #\n",
                "\n",
                "$$\n",
                "\\begin{align*}\n",
                "C(W^\\mathrm{rec}):= \\sum_{k \\in T} \\|x^\\mathrm{target}[k] - x[k]\\|^2\n",
                ",\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "$x^\\mathrm{target}[k]$ は生得的軌道、$T$ はある時間の範囲です。\n",
                "生得的学習ではある初期値 $x^\\mathrm{target}[t_0]$ とある入力に対する時系列をターゲットとして採用するケースが多いです。\n",
                "\n",
                "生得的学習の興味深い点は、カオス性が事前学習後にも完全に抑圧されない点にあります。\n",
                "即ち全体としては系がカオス的にも関わらず、局所的にESPが回復し一定期間高次元な複雑な軌道が再現的に生成されるのです。\n",
                "またデモンストレーションで後ほど示されますが、その高次元なカオス軌道は高い表現能力を有し、様々な軌道を設計できます。\n",
                "またこの高次元カオスは、局所的なパターンのみならず、大域的なパターン間の切り替え則を埋め込み、カオス的遍歴上の軌道を設計できます<sup>[4]</sup>（[論文のコード参照](https://github.com/katsuma-inoue/designing_chaotic_itinerancy_demo)）。\n",
                "\n",
                "[en]: #\n",
                "where $x^\\mathrm{target}[k]$ is an innate trajectory, and $T$ is a time range.\n",
                "In innate training, a time series for a given input with an initial value $x^\\mathrm{target}[t_0]$ is often used as a target.\n",
                "Interestingly, the chaoticity is not completely suppressed even after pre-training.\n",
                "That is, even though the system is globally chaotic, the ESP locally recovers, and high-dimensional complex trajectories are reproducibly generated for a certain period.\n",
                "\n",
                "In addition, as will be shown in the demonstration, the high-dimensional chaotic trajectory has high expressiveness.\n",
                "This high-dimensional chaos can embed not only local patterns but also global switching rules between them<sup>[4]</sup> (see [the code provided by the paper's authors](https://github.com/katsuma-inoue/designing_chaotic_itinerancy_demo))."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "### Full-FORCE\n",
                "\n",
                "[en]: #\n",
                "### Full-FORCE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "B. DePasqualeらによって提案された**Full FORCE**<sup>[2]</sup>もまた、ESNの内部状態を調整するオンライン学習法です。\n",
                "生得的学習とは異なり、カオスESNとその軌道を目標時系列としては使用しません。\n",
                "代わりに以下の式で表される、ある入力 $u^\\mathrm{embed}[k]$ が与えられた際の非カオスESN（ $\\rho<1$ ）の軌道を目標に据えます。\n",
                "\n",
                "[en]: #\n",
                "**Full FORCE**<sup>[2]</sup>, proposed by B. DePasquale et al., is another online learning method that adjusts the internal connections of an ESN.\n",
                "Unlike innate training, it does not use a chaotic ESN and its trajectory as the target time series.\n",
                "Instead, it uses the trajectory of a non-chaotic ESN ($\\rho<1$) with an additional input $u^\\mathrm{embed}[k]$, expressed by the following equation:\n",
                "\n",
                "[END]: #\n",
                "$$\n",
                "\\begin{align*}\n",
                "x^\\mathrm{target}[k+1] &= (1-a)x^\\mathrm{target}[k] + a\\tanh\\left(\\rho W^\\mathrm{rec} x^\\mathrm{target}[k] + W^\\mathrm{in} u^\\mathrm{in}[k]+ W^\\mathrm{embed} u^\\mathrm{embed}[k] \\right)\n",
                ",\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "$u^\\mathrm{embed}[k]$ は埋め込み対象の追加の入力で、 $u^\\mathrm{in}[k]$ の関数であるものを用います。\n",
                "full-FORCEでは、この $u^\\mathrm{embed}[k]$ **なしに** ESNへの埋め込みを目指します。\n",
                "つまりこのときのコスト関数 $C(W^\\mathrm{rec})$ は以下の式で表されます。\n",
                "\n",
                "[en]: #\n",
                "where $u^\\mathrm{embed}[k]$ is an additional input to be embedded and is a function of $u^\\mathrm{in}[k]$.\n",
                "Full-FORCE aims to design an ESN that replicates the dynamics **without** this $u^\\mathrm{embed}[k]$.\n",
                "The cost function $C(W^\\mathrm{rec})$ is expressed as follows:\n",
                "\n",
                "[END]: #\n",
                "\n",
                "$$\n",
                "\\begin{align*}\n",
                "C(W^\\mathrm{rec}):= \\sum_{k \\in T} \\|x^\\mathrm{target}[k] + W^\\mathrm{embed}u^\\mathrm{embed}[k] - x[k]\\|^2\n",
                ",\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "Full-FORCE学習でも事後学習は存在し、追加のリードアウト層が調整されます。\n",
                "full-FORCEの特徴として、この $W^\\mathrm{embed} u^\\mathrm{embed}[k]$ の埋め込みにより、FORCE学習単体より複雑な時系列の設計が可能になる点が挙げられます。\n",
                "このようにfull-FORCEは、内部結合の調整により時系列の設計性を向上させる手法といえます。\n",
                "\n",
                "[en]: #\n",
                "Full-FORCE learning also involves post-training, where an additional readout layer is adjusted.\n",
                "A key feature of full-FORCE is that embedding $W^\\mathrm{embed} u^\\mathrm{embed}[k]$ allows for designing more complex time series compared to FORCE learning alone.\n",
                "In this way, full-FORCE improves the design capability of time series by adjusting the internal connections."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "## 演習問題と実演\n",
                "\n",
                "[en]: #\n",
                "## Exercises and demonstrations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "前回と同様、各種ライブラリおよび実装済みの関数の`import`を行うために次のセルを実行してください。\n",
                "なお内部実装を再確認するには、`import inspect`以下の行をコメントアウトするか`...?? / ??...`を使用してください。\n",
                "\n",
                "[en]: #\n",
                "Execute the following cell to import the classes that we implemented previously, as well as the basic libraries.\n",
                "You can check the internal implementations by uncommenting the lines after `import inspect` or by using `...?? / ??...`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import sys\n",
                "from collections import defaultdict\n",
                "\n",
                "import joblib\n",
                "import numpy as np\n",
                "from IPython.display import clear_output, display\n",
                "from ipywidgets import Output\n",
                "\n",
                "if \"google.colab\" in sys.modules:\n",
                "    from google.colab import drive  # type: ignore\n",
                "\n",
                "    if False:  # Set to True if you want to use Google Drive and save your work there.\n",
                "        drive.mount(\"/content/gdrive\")\n",
                "        %cd /content/gdrive/My Drive/[[PROJECT_NAME]]/\n",
                "        # NOTE: Change it to your own path if you put the zip file elsewhere.\n",
                "        # e.g., %cd /content/gdrive/My Drive/[PATH_TO_EXTRACT]/[[PROJECT_NAME]]/\n",
                "    else:\n",
                "        pass\n",
                "        %cd /content/\n",
                "        !git clone --branch [[BRANCH_NAME]] https://github.com/rc-bootcamp/[[PROJECT_NAME]].git\n",
                "        %cd /content/[[PROJECT_NAME]]/\n",
                "else:\n",
                "    sys.path.append(\".\")\n",
                "\n",
                "from utils.interface import InteractiveViewer\n",
                "from utils.interpolate import interp1d\n",
                "from utils.reservoir import ESN, RidgeReadout, rls_update\n",
                "from utils.style_config import plt\n",
                "from utils.tester import load_from_chapter_name\n",
                "from utils.tqdm import tqdm, trange\n",
                "from utils.viewer import show_innate_error, show_innate_record\n",
                "\n",
                "test_func, show_solution = load_from_chapter_name(\"09_internal_optimization\")\n",
                "\n",
                "\n",
                "# Uncomment it to see the implementations.\n",
                "# import inspect\n",
                "# print(inspect.getsource(Linear))\n",
                "# print(inspect.getsource(RidgeReadout))\n",
                "# print(inspect.getsource(ESN))\n",
                "# print(inspect.getsource(rls_update))\n",
                "\n",
                "# Or just use ??.../...?? (uncomment the following lines).\n",
                "# Linear??\n",
                "# RidgeReadout??\n",
                "# ESN??\n",
                "# rls_update??"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "### 事前学習の実装\n",
                "\n",
                "[en]: #\n",
                "### Implementing pre-training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "まずは 生得的学習の事前学習の実装から始めましょう。\n",
                "先述のとおり生得的学習は、各ノードの前結合を線形閉ループと見なし、FORCE学習を用いて内部結合を調整する手法です。\n",
                "次の式は、$i$ 番目の前結合 ($1\\leq i \\leq N$) に対する FORCE 学習に基づく重み更新則を示しています。\n",
                "\n",
                "[en]: #\n",
                "Let's start by implementing the pre-training process.\n",
                "As mentioned above, innate training considers the pre-synaptic connections of each node as a linear closed loop and adjusts them using FORCE learning.\n",
                "The following equation shows the weight update rule based on FORCE learning for the $i$-th pre-synaptic connection ($1 \\leq i \\leq N$).\n",
                "\n",
                "[END]: #\n",
                "\n",
                "$$\n",
                "\\begin{align*}\n",
                "k^{i} &= P^{i} x^{i} \\\\\n",
                "g^{i} &= \\frac{1}{1+{x^{i}}^\\top k^{i}} \\\\\n",
                "\\Delta P^{i} &= g^{i}{k}^{i}{k^{i}}^\\top \\\\\n",
                "\\Delta W^\\mathrm{rec}_{i~\\cdot} &= g^{i} (\\hat{x}^{i} - {x}^{i}) {k}^{i} \\\\\n",
                "P^{i} &\\leftarrow P^{i} - \\Delta P^{i} \\\\\n",
                "W^\\mathrm{rec}_{i~\\cdot}  &\\leftarrow W^\\mathrm{rec}_{i~\\cdot}  + \\Delta W^\\mathrm{rec}_{i~\\cdot}\n",
                ",\\end{align*}\n",
                "$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "ここで、$P^{i} \\in \\mathbb{R}^{N^{i}\\times N^{i}}$ は ${I}/{\\alpha}$ として初期化された正定値行列であり、$\\hat{x}$ は 生得的軌道です。\n",
                "RLSアルゴリズムに基づくFORCE学習を使用しているため、前章で実装した `rls_update` を再利用できます。\n",
                "ESNの内部結合が疎（`sparse < 1.0`; $p<1.0$ ）であるため、$N^{i}$ は $N$ よりも小さい値を取り ( $N^{i} \\approx p N$ )、計算量が $O(N\\times N^2)$ と比較して大幅に小さい点に注意してください（$O(p^2 N^3)$）。\n",
                "\n",
                "[en]: #\n",
                "where $P^{i} \\in \\mathbb{R}^{N^{i}\\times N^{i}}$ is a positive definite matrix initialized as ${I}/{\\alpha}$, and $\\hat{x}$ is the innate trajectory.\n",
                "Since we use FORCE learning based on the RLS algorithm, we can reuse `rls_update` implemented in the previous chapter.\n",
                "Note that since the internal connections of the ESN are sparse (`sparse < 1.0`, $p < 1.0$), $N^{i}$ takes a smaller value than $N$ ($N^{i} \\approx pN$), which reduces the computational complexity from $O(N \\times N^2)$ to $O(p^2 N^3)$."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Q1.1.\n",
                "\n",
                "[ja]: #\n",
                "以下の穴埋めを実装し、 `InnateESN.__init__` と `InnateESN.train` を完成させよ。\n",
                "\n",
                "[en]: #\n",
                "Complete `InnateESN.__init__` and `InnateESN.train` by filling in the blanks in the following cell.\n",
                "\n",
                "[END]: #\n",
                "\n",
                "- `InnateESN.train`\n",
                "  - Argument(s)\n",
                "    - `x_target`: `np.ndarray`\n",
                "      - innate trajectory $\\hat{x}[k]$ ($\\in \\mathbb{R}^{\\cdots \\times N}$)\n",
                "    - `x_now`: `np.ndarray`\n",
                "      - $x[k]$ ($\\in \\mathbb{R}^{\\cdots \\times N}$)\n",
                "  - Return(s)\n",
                "    - `self.w_net`: `np.ndarray`\n",
                "      - $\\Delta W^\\mathrm{rec}$\n",
                "\n",
                "[ja]: #\n",
                "  - Operation(s)\n",
                "    - `rls_update`を用いた`InnateESN.P`の更新（ $I/\\lambda$ で初期化）\n",
                "    - `InnateESN.w_net` の更新\n",
                "\n",
                "[en]: #\n",
                "  - Operation(s)\n",
                "    - Update `InnateESN.P` ($P^i$) with `rls_update`, which are initialized $I/\\lambda$ in `__init__`.\n",
                "    - Update `InnateESN.w_net` with `rls_update`.\n",
                "\n",
                "[END]: #\n",
                "\n",
                "[tips]: #\n",
                "- [`np.nonzero`](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html)\n",
                "\n",
                "[/tips]: #"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class InnateESN(ESN):\n",
                "    def __init__(self, *args, lmbd=1.0, **kwargs):\n",
                "        \"\"\"\n",
                "        Tunable ESN [Laje, R., & Buonomano, D. V. (2013). Nature neuroscience, 16(7), 925-933.]\n",
                "\n",
                "        Args:\n",
                "            alpha (float, optional): regularization parameter for RLS algorithm. Defaults to 1.0.\n",
                "        \"\"\"\n",
                "        super(InnateESN, self).__init__(*args, **kwargs)\n",
                "        self.w_pre = {}\n",
                "        self.P = {}\n",
                "        for post in range(self.dim):\n",
                "            non_zeros = self.weight[post].nonzero()[0]\n",
                "            self.w_pre[post] = non_zeros\n",
                "            self.P[post] = np.eye(len(self.w_pre[post])) / lmbd  # RIGHT Initialize P matrix for RLS.\n",
                "\n",
                "    def train(self, x_target, x_now=None, node_list=None):\n",
                "        \"\"\"\n",
                "        Update the internal weight by RLS algorithm\n",
                "\n",
                "        Args:\n",
                "            x_target (np.ndarray): State(s) on an inante trajectory.\n",
                "            x_now (np.ndarray, optional): Current state(s). Defaults to None (use self.x).\n",
                "            node_list (list, slice, optional): Tuned nodes. Defaults to None (train all nodes).\n",
                "        \"\"\"\n",
                "        if x_now is None:\n",
                "            x_now = np.asarray(self.x)\n",
                "        if node_list is None:\n",
                "            node_list = range(self.dim)\n",
                "        for xt, xn in zip(x_target.reshape(-1, self.dim), x_now.reshape(-1, self.dim), strict=False):\n",
                "            es = xt[node_list] - xn[node_list]\n",
                "            for node_id, e in zip(node_list, es, strict=False):\n",
                "                x = xn[self.w_pre[node_id]]  # RIGHT Use self.w_pre (hint: `x = xn[...]`).\n",
                "                P = self.P[node_id]  # RIGHT Get P matrix for the node (hint: `P = self.P[...]`).\n",
                "                g, k, P_new = rls_update(P, x)  # RIGHT Use `rls_update`.\n",
                "                dw = g * np.outer(e, k)  # RIGHT Calculate dw (hint: use `g`, `e`, and `k`).\n",
                "                self.P[node_id] = P_new\n",
                "                self.weight[node_id, self.w_pre[node_id]] += dw[0]\n",
                "        return self.weight\n",
                "\n",
                "    def to_pickle(self, file_name):\n",
                "        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
                "        P, w_pre = self.P, self.w_pre\n",
                "        self.P, self.w_pre = {}, {}\n",
                "        with open(file_name, mode=\"wb\") as f:\n",
                "            joblib.dump(self, f, compress=True)\n",
                "        self.P, self.w_pre = P, w_pre\n",
                "\n",
                "    @staticmethod\n",
                "    def read_pickle(file_name):\n",
                "        with open(file_name, mode=\"rb\") as f:\n",
                "            module = joblib.load(f)\n",
                "        return module\n",
                "\n",
                "\n",
                "def solution(dim, seed, x_target, x_now, node_list):\n",
                "    # DO NOT CHANGE HERE.\n",
                "    net = InnateESN(dim, seed=seed, node_list=node_list)\n",
                "    net.train(x_target=x_target, x_now=x_now, node_list=node_list)\n",
                "    return net.weight\n",
                "\n",
                "\n",
                "test_func(solution, \"01_01\")\n",
                "# show_solution(\"01_01\", \"InnateESN\")  # Uncomment it to see the solution."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Q1.2.\n",
                "\n",
                "[ja]: #\n",
                "生得的学習の事前学習を実装する `emulate_innate` を実装せよ。\n",
                "ただし $k \\in [t_\\mathrm{b}, t_\\mathrm{e}) \\land k \\equiv 0~ (\\mathrm{mod}~t_\\mathrm{every}) $ のときに `InnateESN.train` によって $W^\\mathrm{rec}$ を更新、それ以外のときは何もしない。\n",
                "\n",
                "[en]: #\n",
                "Implement `emulate_innate` by filling in the blank in the following cell.\n",
                "It will update $W^\\mathrm{rec}$ using `InnateESN.train` when $k \\in [t_\\mathrm{b}, t_\\mathrm{e}) \\land k \\equiv 0~ (\\mathrm{mod}~t_\\mathrm{every})$, and do nothing otherwise.\n",
                "\n",
                "[END]: #\n",
                "\n",
                "- `emulate_innate`\n",
                "  - Argument(s):\n",
                "    - `ts`: `list | np.ndarray`\n",
                "    - `net`: `InnateESN`\n",
                "    - `f_in`: `Callable`\n",
                "      - $f^\\text{in}(t)$\n",
                "    - `innate_range`: `tuple(int, int)`\n",
                "      - $[t_\\mathrm{b}, t_\\mathrm{e})$\n",
                "    - `innate_node`: `list | slice`\n",
                "    - `innate_every`: `int`\n",
                "      - $t_\\mathrm{every}$\n",
                "    - `innate_func`: `Callable`\n",
                "      - $\\hat{x}: T \\to \\mathbb{R}^{\\cdots \\times N}$\n",
                "  - Return(s):\n",
                "    - `record`: `dict`\n",
                "      - `'t'`: `np.ndarray`\n",
                "        - $[t_0, t_1,~\\ldots,~t_{T-1}]$\n",
                "      - `'x'`: `np.ndarray`\n",
                "        - $[x[t_0], x[t_1],~\\ldots,~x[t_{T-1}]]$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def emulate_innate(\n",
                "    ts,\n",
                "    net,\n",
                "    f_in=None,\n",
                "    innate_range=None,\n",
                "    innate_func=None,\n",
                "    innate_node=None,\n",
                "    innate_every=2,\n",
                "    prefix=\"\",\n",
                "    leave=True,\n",
                "    display=True,\n",
                "):\n",
                "    record = {}\n",
                "    record[\"t\"] = np.zeros(len(ts), dtype=int)\n",
                "    record[\"x\"] = np.zeros((len(ts), *net.x.shape))\n",
                "    pbar = tqdm(ts, leave=leave, display=display)\n",
                "    for cnt, t in enumerate(pbar):\n",
                "        pbar.set_description(\"{}t={:.0f}\".format(prefix, t))\n",
                "        u_in = np.zeros_like(net.x)\n",
                "        if f_in is not None:\n",
                "            u_in += f_in(t)\n",
                "        net.step(u_in)\n",
                "        record[\"t\"][cnt] = t\n",
                "        record[\"x\"][cnt] = net.x\n",
                "        if (innate_range is not None) and (innate_range[0] <= t < innate_range[1]):\n",
                "            if cnt % innate_every == 0:\n",
                "                # BEGIN Use `net.train` and specify `node_list=innate_node`.\n",
                "                x_target = innate_func(t)\n",
                "                net.train(x_target, node_list=innate_node)\n",
                "                # END\n",
                "    return record\n",
                "\n",
                "\n",
                "def solution(ts, dim, seed, **kwargs):\n",
                "    # DO NOT CHANGE HERE.\n",
                "    net = InnateESN(dim, seed=seed)\n",
                "    record = emulate_innate(ts, net, **kwargs)\n",
                "    return record[\"x\"]\n",
                "\n",
                "\n",
                "test_func(solution, \"01_02\")\n",
                "# show_solution(\"01_02\", \"emulate_innate\")  # Uncomment it to see the solution."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "`emulate_innate` が準備できたら以下のセルを実行してください。\n",
                "\n",
                "- `create_target`: 生得的軌道の生成\n",
                "- `train_network`: 事前学習の実行\n",
                "- `eval_newtork`: 事前学習の評価\n",
                "- `eval_error`: MSEならびにNRMSEの評価\n",
                "\n",
                "[en]: #\n",
                "Run the following cell.\n",
                "\n",
                "- `create_target`: Generate the innate trajectory.\n",
                "- `train_network`: Run the pre-training.\n",
                "- `eval_network`: Evaluate the pre-trained network.\n",
                "- `eval_error`: Evaluate the MSE and NRMSE between the innate trajectory and the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_target(record_range, net, f_in, rnd=None):\n",
                "    rnd = rnd if rnd else np.random.default_rng()\n",
                "    net.x = rnd.uniform(low=-1, high=1, size=(f_in.dim, net.dim))\n",
                "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"sample \")\n",
                "    return record\n",
                "\n",
                "\n",
                "def train_network(record_range, net, f_in, rec_target, innate_range, innate_node, innate_every, rnd=None):\n",
                "    rnd = rnd if rnd else np.random.default_rng()\n",
                "    innate_func = interp1d(rec_target[\"x\"], x=rec_target[\"t\"], kind=1, axis=0)\n",
                "    net.x = rnd.uniform(low=-1, high=1, size=(f_in.dim, net.dim))\n",
                "    record = emulate_innate(\n",
                "        range(*record_range),\n",
                "        net,\n",
                "        f_in=f_in,\n",
                "        prefix=\"train \",\n",
                "        innate_func=innate_func,\n",
                "        innate_node=innate_node,\n",
                "        innate_range=innate_range,\n",
                "        innate_every=innate_every,\n",
                "    )\n",
                "    return record\n",
                "\n",
                "\n",
                "def eval_network(record_range, net, f_in, eval_num=5, rnd=None):\n",
                "    rnd = rnd if rnd else np.random.default_rng()\n",
                "    net.x = rnd.uniform(low=-1, high=1, size=(eval_num, f_in.dim, net.dim))\n",
                "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"eval \")\n",
                "    return record\n",
                "\n",
                "\n",
                "def eval_error(rec_eval, rec_target, innate_range, innate_node):\n",
                "    begin_id = int(innate_range[0] - rec_eval[\"t\"][0])\n",
                "    end_id = int(innate_range[1] - rec_eval[\"t\"][0])\n",
                "    diff = rec_eval[\"x\"] - rec_target[\"x\"][:, None]  # -> [Time_steps, Eval_num, w_pulse_num, Net_dim]\n",
                "    norm = (diff[begin_id:end_id, ..., innate_node] ** 2).sum(axis=-1)  # -> [T, E, W]\n",
                "    mse = norm.mean(axis=0)  # -> [E, W]\n",
                "\n",
                "    var = (rec_target[\"x\"][begin_id:end_id, ..., innate_node] ** 2).sum(axis=(0, 2))  # -> [W]\n",
                "    nrmse = (norm.sum(axis=0) / var) ** 0.5  # -> [E, W]\n",
                "    return {\"mse\": mse, \"nrmse\": nrmse}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "### 事前学習の実行\n",
                "\n",
                "[en]: #\n",
                "### Run pre-training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "ここからデモンストレーションに移ります。\n",
                "まず実験パラメータを指定します。\n",
                "また事前学習に非常に時間がかかるため、出力フォルダ `save_dir` （デフォルトでは`./output`）を作成し、実験条件と結果を保存します。\n",
                "\n",
                "[en]: #\n",
                "Let's move on to the demonstration.\n",
                "\n",
                "First, specify the experimental parameters.\n",
                "Since pre-training might take a long time, the following cells create an output folder `save_dir` (`./output` by default) to allow restoring the results even after it halts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "save_dir = \"./result\"\n",
                "os.makedirs(save_dir, exist_ok=True)\n",
                "\n",
                "seed = 1234\n",
                "\n",
                "w_pulse_num = 1\n",
                "dim, a, sr, p = 1000, 0.1, 1.6, 0.2\n",
                "pulse_amp, pulse_period = 10.0, 50\n",
                "\n",
                "alpha = 1.0\n",
                "innate_epoch = 20\n",
                "innate_period, innate_rate, innate_every = 3000, 0.1, 4\n",
                "washout_period, record_period = 1000, 5000\n",
                "\n",
                "rnd = np.random.default_rng(seed)\n",
                "net = InnateESN(dim, a=a, sr=sr, p=p, alpha=alpha, rnd=rnd)\n",
                "w_pulse = rnd.uniform(size=(w_pulse_num + 2, dim), low=-1.0, high=1.0)\n",
                "\n",
                "innate_range = [0, innate_period]\n",
                "innate_node = list(range(0, int(innate_rate * net.dim)))\n",
                "record_range = [-washout_period, record_period]\n",
                "pulse_range = [-pulse_period, 0]\n",
                "\n",
                "plot_range = list(range(5))\n",
                "\n",
                "\n",
                "def f_in(t):\n",
                "    if -pulse_period <= t < 0:\n",
                "        return pulse_amp * w_pulse[:w_pulse_num]\n",
                "    else:\n",
                "        return 0.0\n",
                "\n",
                "\n",
                "f_in.dim = w_pulse_num\n",
                "\n",
                "with open(f\"{save_dir}/params.json\", mode=\"w\") as f:\n",
                "    json.dump(\n",
                "        {\n",
                "            \"pulse_amp\": pulse_amp,\n",
                "            \"pulse_period\": pulse_period,\n",
                "            \"innate_period\": innate_period,\n",
                "            \"innate_rate\": innate_rate,\n",
                "            \"innate_every\": innate_every,\n",
                "        },\n",
                "        f,\n",
                "        indent=4,\n",
                "    )\n",
                "\n",
                "np.save(f\"{save_dir}/w_pulse.npy\", w_pulse)\n",
                "net.to_pickle(f\"{save_dir}/net_init.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "まずは生得的軌道 $\\hat{x}[k]$ を生成します。\n",
                "\n",
                "[en]: #\n",
                "The following cell will generate the innate trajectory $\\hat{x}[k]$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rec_target = create_target(record_range, net, f_in, rnd=rnd)\n",
                "fig_target = show_innate_record(\n",
                "    rec_target,\n",
                "    plot_range,\n",
                "    lw=1.5,\n",
                "    color=\"k\",\n",
                "    title=\"innate trajectory\",\n",
                "    pulse_range=pulse_range,\n",
                "    innate_range=innate_range,\n",
                ")\n",
                "np.savez_compressed(f\"{save_dir}/rec_target.npz\", *rec_target)\n",
                "fig_target.savefig(f\"{save_dir}/rec_target.png\", dpi=200)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "灰色の領域は、パルス入力が与えられた期間を表します。\n",
                "ピンク色の領域は、事前学習期間 $[t_\\mathrm{b}, t_\\mathrm{e})$ を表します。\n",
                "\n",
                "[en]: #\n",
                "The gray area represents the period when the pulse input is given.\n",
                "The pink area shows the pre-training period $[t_\\mathrm{b}, t_\\mathrm{e})$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def eval_network(record_range, net, f_in, eval_num=5, rnd=None):  # noqa: F811\n",
                "    rnd = rnd if rnd else np.random.default_rng()\n",
                "    net.x = rnd.uniform(low=-1, high=1, size=(eval_num, f_in.dim, net.dim))\n",
                "    record = emulate_innate(range(*record_range), net, f_in=f_in, prefix=\"eval \")\n",
                "    return record\n",
                "\n",
                "\n",
                "rec_init = eval_network(record_range, net, f_in, rnd=rnd)\n",
                "fig = show_innate_record(\n",
                "    rec_target,\n",
                "    plot_range,\n",
                "    lw=1.5,\n",
                "    ls=\":\",\n",
                "    clear=True,\n",
                "    color=\"k\",\n",
                "    pulse_range=pulse_range,\n",
                "    innate_range=innate_range,\n",
                ")\n",
                "fig = show_innate_record(\n",
                "    rec_init,\n",
                "    plot_range,\n",
                "    lw=0.5,\n",
                "    ls=\"-\",\n",
                "    fig=fig,\n",
                "    cmap=plt.get_cmap(\"tab10\"),\n",
                "    title=\"eval (before pre-training)\",\n",
                ")\n",
                "fig.savefig(f\"{save_dir}/eval/init.png\", dpi=200)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "この図より、生得的軌道 (点線) をESNが現時点では再現的に生成できない様子が読み取れます。\n",
                "\n",
                "以下のセルは事前学習を実行します。\n",
                "20〜30分はかかりますので、終了するまでお待ちください。\n",
                "\n",
                "[en]: #\n",
                "This figure shows that the ESN cannot reproducibly generate the innate trajectories (dotted lines) at this point.\n",
                "\n",
                "The following cell runs the pre-training iteratively.\n",
                "This will take 20-30 minutes, so please wait until it finishes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "record = {}\n",
                "best_score = np.array(np.inf)\n",
                "figs = defaultdict(lambda: None)\n",
                "\n",
                "pbar = trange(innate_epoch)\n",
                "out_tqdm, out_figure = Output(), Output()\n",
                "display(out_tqdm)\n",
                "display(out_figure)\n",
                "for epoch in pbar:\n",
                "    pbar.set_description(\"best:{:.2e}\".format(best_score))\n",
                "    with out_tqdm:\n",
                "        clear_output(wait=True)\n",
                "        # Training phase\n",
                "        rec_train = train_network(\n",
                "            record_range,\n",
                "            net,\n",
                "            f_in,\n",
                "            rec_target,\n",
                "            innate_range,\n",
                "            innate_node,\n",
                "            innate_every,\n",
                "            rnd=rnd,\n",
                "        )\n",
                "        figs[\"train\"] = show_innate_record(\n",
                "            rec_target,\n",
                "            plot_range,\n",
                "            lw=1.5,\n",
                "            ls=\":\",\n",
                "            clear=True,\n",
                "            color=\"black\",\n",
                "            fig=figs[\"train\"],\n",
                "            pulse_range=pulse_range,\n",
                "            innate_range=innate_range,\n",
                "        )\n",
                "        figs[\"train\"] = show_innate_record(\n",
                "            rec_train,\n",
                "            plot_range,\n",
                "            lw=1.0,\n",
                "            ls=\"-\",\n",
                "            fig=figs[\"train\"],\n",
                "            cmap=plt.get_cmap(\"tab10\"),\n",
                "            title=f\"train (epoch #{epoch})\",\n",
                "        )\n",
                "        figs[\"train\"].savefig(\"{}/train/{:03d}.png\".format(save_dir, epoch), dpi=200)\n",
                "\n",
                "        # Evaluation phase\n",
                "        rec_eval = eval_network(record_range, net, f_in, rnd=rnd)\n",
                "        figs[\"eval\"] = show_innate_record(\n",
                "            rec_target,\n",
                "            plot_range,\n",
                "            lw=1.5,\n",
                "            ls=\":\",\n",
                "            clear=True,\n",
                "            color=\"black\",\n",
                "            fig=figs[\"eval\"],\n",
                "            pulse_range=pulse_range,\n",
                "            innate_range=innate_range,\n",
                "        )\n",
                "        figs[\"eval\"] = show_innate_record(\n",
                "            rec_eval,\n",
                "            plot_range,\n",
                "            lw=0.5,\n",
                "            ls=\"-\",\n",
                "            fig=figs[\"eval\"],\n",
                "            cmap=plt.get_cmap(\"tab10\"),\n",
                "            title=f\"eval (epoch #{epoch})\",\n",
                "        )\n",
                "        figs[\"eval\"].savefig(\"{}/eval/{:03d}.png\".format(save_dir, epoch), dpi=200)\n",
                "\n",
                "        # Record evaluation error\n",
                "        rec = eval_error(rec_eval, rec_target, innate_range, innate_node)\n",
                "        best_score = min(best_score, rec[\"nrmse\"].sum())\n",
                "        rec[\"best\"] = best_score\n",
                "\n",
                "        for key, val in rec.items():\n",
                "            if key not in record:\n",
                "                record[key] = np.zeros((innate_epoch, *val.shape))\n",
                "            record[key][epoch] = val\n",
                "\n",
                "    with out_figure:\n",
                "        clear_output(wait=True)\n",
                "        figs[\"nrmse\"] = show_innate_error(record[\"nrmse\"][: epoch + 1], fig=figs[\"nrmse\"])\n",
                "        figs[\"nrmse\"].savefig(f\"{save_dir}/nrmse.png\", dpi=200)\n",
                "        for _name, fig in figs.items():\n",
                "            size = fig.get_size_inches()\n",
                "            fig.set_size_inches(8, 3)\n",
                "            display(fig)\n",
                "            fig.set_size_inches(size)\n",
                "\n",
                "net.to_pickle(f\"{save_dir}/net_term.pkl\")\n",
                "np.savez_compressed(f\"{save_dir}/record.npz\", **record)\n",
                "\n",
                "for _name, fig in figs.items():\n",
                "    fig.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "徐々に、異なる初期値にもかかわらず、複雑な高次元カオスを再現的に生成できる様子が見て取れると思います。\n",
                "`{save_dir}/eval` 内に保存されている図を確認してください。\n",
                "\n",
                "[en]: #\n",
                "You will see that the ESN gradually becomes able to reproducibly generate complex high-dimensional chaos despite different initial values.\n",
                "Check the figures saved in `{save_dir}/eval`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Q1.3. (Advanced)\n",
                "\n",
                "[ja]: #\n",
                "- ノード数を変化させ、MSEの違いを観察せよ。\n",
                "- より長い `innate_period` を試し、事前学習の性能を比較せよ。\n",
                "- `w_pulse_num` を増やし、複数の入力に対して事前学習せよ。\n",
                "\n",
                "[en]: #\n",
                "- Vary the number of nodes and observe the differences in MSE.\n",
                "- Try a longer `innate_period` and compare the pre-training performance.\n",
                "- Increase `w_pulse_num` and pre-train with multiple inputs."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "### 事後学習の実装\n",
                "\n",
                "[en]: #\n",
                "### Implementing post-training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "事前学習したESNを用いて、リードアウト層を学習しましょう。\n",
                "以下のセルは`{load_dir}/net_term.pkl`に保存されたESNと、`{load_dir}/params.json` に保存されたパラメータファイルを読み込みます。\n",
                "事前学習済みの場合は前のセルをスキップして、ここから開始可能です。\n",
                "\n",
                "[en]: #\n",
                "Let's train the readout layer using a pre-trained ESN.\n",
                "The following cell loads the ESN saved in `{load_dir}/net_term.pkl` and the parameter file saved in `{load_dir}/params.json`.\n",
                "You can skip the previous cell and start from here if you have already completed the pre-training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dir = \"./result\"\n",
                "\n",
                "net_init = InnateESN.read_pickle(f\"{load_dir}/net_init.pkl\")\n",
                "net_term = InnateESN.read_pickle(f\"{load_dir}/net_term.pkl\")\n",
                "w_pulse = np.load(f\"{load_dir}/w_pulse.npy\")\n",
                "with open(f\"{load_dir}/params.json\", mode=\"r\") as f:\n",
                "    params = json.load(f)\n",
                "\n",
                "pulse_amp = params[\"pulse_amp\"]\n",
                "pulse_period = params[\"pulse_period\"]\n",
                "innate_period = params[\"innate_period\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "以下のセルは、事前学習前と後のESNの軌道を比較します。\n",
                "\n",
                "[en]: #\n",
                "The following cell compares the trajectories of the ESN before and after pre-training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "seed = 1234\n",
                "w_pulse_num = 1\n",
                "washout_period, record_period = 1000, 10000\n",
                "record_range = [-washout_period, record_period]\n",
                "pulse_range = [-pulse_period, 0]\n",
                "innate_range = [0, innate_period]\n",
                "plot_range = list(range(5))\n",
                "\n",
                "rnd = np.random.default_rng(seed)\n",
                "\n",
                "\n",
                "def f_in(t):\n",
                "    if -pulse_period <= t < 0:\n",
                "        return pulse_amp * w_pulse[:w_pulse_num]\n",
                "    else:\n",
                "        return 0.0\n",
                "\n",
                "\n",
                "f_in.dim = w_pulse_num\n",
                "\n",
                "rec_sample_init = eval_network(record_range, net_init, f_in, rnd=rnd)\n",
                "fig = show_innate_record(\n",
                "    rec_sample_init,\n",
                "    plot_range,\n",
                "    lw=1.0,\n",
                "    title=\"initial\",\n",
                "    pulse_range=pulse_range,\n",
                "    innate_range=innate_range,\n",
                ")\n",
                "\n",
                "rec_sample_term = eval_network(record_range, net_term, f_in, rnd=rnd)\n",
                "fig = show_innate_record(\n",
                "    rec_sample_term,\n",
                "    plot_range,\n",
                "    lw=1.0,\n",
                "    title=\"pre-trained\",\n",
                "    pulse_range=pulse_range,\n",
                "    innate_range=innate_range,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "次に目標となるリードアウト層の出力時系列を用意しましょう。\n",
                "`./data/09_internal_optimization`以下には`abc.csv`と`star.csv`が用意されています。\n",
                "今回は`abc.csv`を使用してみましょう。\n",
                "\n",
                "[en]: #\n",
                "Next, let's prepare the target output time series for the readout layer.\n",
                "`abc.csv` and `star.csv` are available in `./data/09_internal_optimization`.\n",
                "Let's use `abc.csv` this time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = np.loadtxt(\"./data/09_internal_optimization/abc.csv\", delimiter=\",\")\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "ax.plot(data[:, 0], data[:, 1])\n",
                "ax.set_aspect(\"equal\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "事前学習したESNは、入力後 $t\\in[0, t_\\mathrm{innate})$ の期間再現的にinnate trajectoryを生成します。\n",
                "これをリードアウト層を用いて線型回帰により対応付けましょう。\n",
                "\n",
                "[en]: #\n",
                "The pre-trained ESN reproducibly generates innate trajectories for $t\\in[0, t_\\mathrm{innate})$ after the input is given.\n",
                "The following cell trains the readout layer to map this high-dimensional chaos to the prepared time series."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ts, xs = rec_sample_term[\"t\"], rec_sample_term[\"x\"]\n",
                "\n",
                "x_train = xs[washout_period : washout_period + innate_period, :, 0, :]\n",
                "\n",
                "target_func = interp1d(data, kind=1, axis=0)\n",
                "ds = target_func(np.linspace(0, 1, innate_period))\n",
                "ds = np.broadcast_to(ds[:, None, :], (*x_train.shape[:-1], ds.shape[-1]))\n",
                "\n",
                "w_out = RidgeReadout(net_term.dim, 2, lmbd=1e-2)\n",
                "weight, bias = w_out.train(x_train.reshape(-1, x_train.shape[-1]), ds.reshape(-1, ds.shape[-1]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "`InteractiveView` は動的に入力を与えられるツールです。\n",
                "以下のセルを実行し、パルス入力後に適切に目標軌道が出力されるか確認してください。\n",
                "\n",
                "[en]: #\n",
                "`InteractiveView` is an interface where you can interactively give inputs.\n",
                "Run the following cell and check that the target trajectory `abc.csv` is properly output after the input is given."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib widget\n",
                "\n",
                "import copy\n",
                "\n",
                "try:\n",
                "    del viewer  # type: ignore\n",
                "except NameError:\n",
                "    pass\n",
                "\n",
                "net_term_cp = copy.deepcopy(net_term)\n",
                "\n",
                "net_term_cp.x = rnd.uniform(-1, 1, net_term_cp.dim)\n",
                "viewer = InteractiveViewer(\n",
                "    net_term_cp,\n",
                "    w_out,\n",
                "    w_pulse,\n",
                "    pulse_amp,\n",
                "    pulse_period,\n",
                "    plot_num=5,\n",
                "    input_num=w_pulse_num,\n",
                "    max_time_steps=10000,\n",
                "    cmap=\"Greens\",\n",
                ")\n",
                "\n",
                "viewer.view()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Q2.1. (Advanced)\n",
                "\n",
                "[ja]: #\n",
                "- `InteractiveView` の引数 `input_num` の数を増やすと入力の種類を増やせる。\n",
                "ただ現時点では学習されていないため、意味のない出力しか得られない。\n",
                "入力の数を2に増やし（`w_pulse_num=2`）、別の入力に対しては「星」（`star.csv`）を出力するように事前学習と事後学習を行え (僅かな変更で実装できる) 。\n",
                "\n",
                "[en]: #\n",
                "- By increasing the `input_num` argument in `InteractiveView`, you can increase the number of input types. However, the network has not been trained for these inputs yet, so only meaningless outputs will be obtained. Increase the number of inputs to 2 (`w_pulse_num=2`) and perform both pre-training and post-training so that a different input generates a \"star\" output (`star.csv`) (this can be done with minor modifications)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Q2.2. (Advanced)\n",
                "\n",
                "[ja]: #\n",
                "- Innate trainingとほとんどコードを改変せずにFull FORCEを実装できる。[2]を参考に、`InnateESN`を継承した`FullFORCEESN`を実装せよ。\n",
                "\n",
                "[en]: #\n",
                "- Full FORCE can be implemented with almost no code changes from innate training. Implement `FullFORCEESN` inheriting from `InnateESN` by referring to [2]."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[ja]: #\n",
                "## 参考文献\n",
                "\n",
                "[en]: #\n",
                "## References"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[1] Laje, R., & Buonomano, D. V. (2013). *Robust timing and motor patterns by taming chaos in recurrent neural networks*. Nature Neuroscience, 16(7), 925–933. https://doi.org/10.1038/nn.3405\n",
                "\n",
                "[2] DePasquale, B., Cueva, C. J., Rajan, K., Escola, G. S., & Abbott, L. F. (2018). *full-FORCE: A target-based method for training recurrent networks*. PLOS ONE, 13(2), e0191527. https://doi.org/10.1371/journal.pone.0191527\n",
                "\n",
                "[3] Sussillo, D., & Abbott, L. F. (2009). *Generating Coherent Patterns of Activity from Chaotic Neural Networks*. Neuron, 63(4), 544–557. https://doi.org/10.1016/j.neuron.2009.07.018\n",
                "\n",
                "[4] Inoue, K., Nakajima, K., & Kuniyoshi, Y. (2020). *Designing spontaneous behavioral switching via chaotic itinerancy*. Science Advances, 6(46), eabb3989. https://doi.org/10.1126/sciadv.abb3989"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "rc-bootcamp (3.12.12)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
